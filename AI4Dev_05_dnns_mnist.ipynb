{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/maurapintor/ai4dev/blob/main/AI4Dev_05_dnns_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning from images\n",
        "\n",
        "In this notebook, we will load a dataset of images and go back to the classification problem.\n",
        "\n",
        "We will load the MNIST dataset, a (labeled) dataset of images of handwritten digits. We can use the `torchvision` library to load and process data in the image domain. Additionally, we can use `matplotlib` for visualization and `pillow` for processing them.\n",
        "\n",
        "We will also inspect how data can be loaded in PyTorch, how to create batches of images rather than passing the whole dataset at once, and also how to implement the learning phase (this last part won't be much different than the previous notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "_fkvuH4z65Z1",
        "outputId": "b680b6be-7e0d-477a-a22e-03a09caf0a13"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data_path = 'data'\n",
        "mnist_train = ...\n",
        "\n",
        "mnist_validation = datasets.MNIST(data_path,\n",
        "                                  train=False,\n",
        "                                  download=True)\n",
        "\n",
        "print(\"samples in training dataset: \", len(mnist_train))\n",
        "print(\"samples in testing dataset: \", len(mnist_validation))\n",
        "\n",
        "# first sample\n",
        "image, label = mnist_train[0]\n",
        "print(\"shape of sample\")\n",
        "print(np.array(image).shape)\n",
        "\n",
        "# visualize the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f\"Sample label: {label}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In torchvision we also have tools to preprocess the images, as well as converting them directly to PyTorch tensors.\n",
        "As we load the image and convert to tensor, we can also inspect what changed. First, the shape now includes an additional dimension that is the batch index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdbK9BL59sbQ",
        "outputId": "98f372b1-d645-4d7f-ec6d-6bd76c5ca948"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "to_tensor = ...\n",
        "image_as_tensor = ...\n",
        "print(image_as_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Additionally, we can also apply transformations to the images. These are in general useful if we want the model to generalize across different modifications of the samples, rather than learning only from well-placed input data.\n",
        "\n",
        "We also define a function to visualize the image so that we can easily display it by passing a tensor without repeating lines of code in our notebook (matplotlib requires images in the format CHW - channels, height, width while pytorch encodes as HWC)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "aZeHUguQ_p5B",
        "outputId": "a2774788-3a05-4466-d90b-dab129b67c89"
      },
      "outputs": [],
      "source": [
        "# random rotation between 0 an 90 degrees\n",
        "rotation = transforms.RandomRotation(90)\n",
        "rotated = rotation(image_as_tensor)\n",
        "\n",
        "def display_image(image, label):\n",
        "    # permute required to transform back in the PIL format\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(f\"Sample label: {label}\")\n",
        "    plt.show()\n",
        "\n",
        "display_image(rotated, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also include the transforms in the dataset constructor, and then they will be applied to each sample upon loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7XmxStFBFZW",
        "outputId": "92cc95c3-58c7-405b-eca1-acb0a4e55266"
      },
      "outputs": [],
      "source": [
        "tensor_mnist_train = datasets.MNIST(data_path,\n",
        "                                    train=True,\n",
        "                                    download=False,\n",
        "                                    transform=...)\n",
        "\n",
        "sample, label = tensor_mnist_train[0]\n",
        "\n",
        "print(\"Sample type (as python object)\")\n",
        "print(type(sample))\n",
        "\n",
        "print(\"Sample dtype (of the elements)\")\n",
        "print(sample.dtype)\n",
        "\n",
        "print(\"Sample shape\")\n",
        "print(sample.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also, note that  the rescaling automatic if the inputs are recognized as images. This means that the images are automatically converted to Tensor and the pixels are divided by 255 (as [0, 255] is the range of values for the pixels). In this way, the values will become floating points in [0,1].\n",
        "\n",
        "Reference:\n",
        "- https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceECVslBBvG5",
        "outputId": "ba012e68-1ced-4771-cefd-039c83bd9ad0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "print(f\"image min: {np.array(image).min()}, image max: {np.array(image).max()}, dtype: {np.array(image).dtype}\")\n",
        "print(f\"tensor min: {sample.min()}, tensor max: {sample.max()}, dtype: {sample.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to normalize the data with zero mean and standard deviation equal to 1, we have to compute these values on the training dataset and then apply the same transformation to the testing data. \n",
        "Here is the code to compute the mean and standard deviations for all features of the MNIST dataset. Note that when images contain three channels (RGB images), the values of mean and standard deviation are computed for each channel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp23ub73c9M9",
        "outputId": "95d1f958-ff51-47e7-ad35-d742951bd15d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "dataset = torch.stack([sample for sample, _ in tensor_mnist_train], dim=3)\n",
        "\n",
        "print(\"dataset shape:\")\n",
        "print(dataset.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "means = ...\n",
        "stds = ...\n",
        "\n",
        "print(f\"means: {means}\")\n",
        "print(f\"stds: {stds}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can initialize the transform with the correct values (and we can make sure they are correct after transformation). If we want to apply more than one transformation, we can use the `torchvision.transforms.Compose` to chain the transformations (which will be applied in sequence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdPQAvd1dg9S",
        "outputId": "c978dcbd-4db7-4fc3-be41-231e395c77a1"
      },
      "outputs": [],
      "source": [
        "normalize = ...\n",
        "transformed_mnist_train = datasets.MNIST(data_path, train=True,\n",
        "                                         download=False,\n",
        "                                         transform=transforms.Compose([\n",
        "                                         transforms.ToTensor(),\n",
        "                                         normalize,]))\n",
        "\n",
        "dataset = torch.stack([sample for sample, _ in transformed_mnist_train], dim=3)\n",
        "\n",
        "#Â let's verify that the mean and standard deviation are now as we want them\n",
        "means = dataset.view(1, -1).mean(dim=1)\n",
        "stds = dataset.view(1, -1).std(dim=1)\n",
        "print(f\"mean: {means}\")\n",
        "print(f\"std: {stds}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have our data normalized, we can create a model to classify the images.\n",
        "\n",
        "Here are some important details:\n",
        "- In the first layer, we have 784 features, while our images are 28x28. We first have to flatten the input (and take care that the batch size stays the same)\n",
        "- Note that the model can (and should) process data in batches, thus the code should be independent from the batch size. This is why in the first step of the transform we have a -1 as the first argument of the `view` method. This -1 means that we leave the first dimension as it is, and we reshape the others to fit the new shape.\n",
        "- The number of outputs is equal to the number of classes, as we want one node for each of the classes. We will pick the \"winner\" as the top score in the output of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-BAOS89hThL",
        "outputId": "5c87739c-08c4-4494-c5ee-156123646138"
      },
      "outputs": [],
      "source": [
        "class MNISTModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # we have to flatten the samples that are 28x28\n",
        "        ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can create our model and predict the label for one sample. Note that the model is not yet trained, so the output will be basically random. Also, the output has shape (n_samples, n_classes). To get the prediction for each sample (in this case it's only one, but let's make it in a way that will work also for batches), we can use the `tensor.argmax()` method. If we specify the argument `dim=1` we can take the argument of the maximum for each row (i.e., the predicted classes, as desired)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "net = MNISTModel()\n",
        "sample, label = transformed_mnist_train[0]\n",
        "\n",
        "# prediction from untrained model\n",
        "out = ...\n",
        "print(\"scores:\", out)\n",
        "\n",
        "# predicted class\n",
        "pred = ...\n",
        "print(\"predicted class:\", pred.item())\n",
        "print(\"original label: \", label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For loading the data in batches, rather than single samples or entire datasets, we can use the `DataLoader` from `torch.utils.data`. We can specify the batch size of each batch here (i.e., how many images for each batch), and also whether to shuffle the indexes or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-zsg64UlSf7"
      },
      "outputs": [],
      "source": [
        "transformed_mnist_validation = datasets.MNIST(data_path, train=False,\n",
        "                                              download=False,\n",
        "                                              transform=transforms.Compose([\n",
        "                                              transforms.ToTensor(),\n",
        "                                              normalize,]))  # same normalize as train\n",
        "\n",
        "train_loader = ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_loader = torch.utils.data.DataLoader(transformed_mnist_validation,\n",
        "                                         batch_size=64,\n",
        "                                         shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can write our training loop as usual. Compared to our previous example with regression, in this case we are going to use the cross-entropy loss.\n",
        "\n",
        "$$\n",
        "L = - \\sum_{c=1}^{C} y_c log(p_c)\n",
        "$$\n",
        "\n",
        "Where we loop through the classes and compare the prediction $p_c$ with the desired label $y_c$. This is implemented in PyTorch, so we only have to take care of instantiating the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuWkoFcqmBNH",
        "outputId": "7958470c-223b-46d8-9557-0284395564c1"
      },
      "outputs": [],
      "source": [
        "net = MNISTModel()\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 8], gamma=0.5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "epochs = 10\n",
        "\n",
        "# train\n",
        "for epoch in range(epochs):\n",
        "    for samples, labels in train_loader:\n",
        "        ...\n",
        "        loss = ...\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to check how our model behaves, we cannot directly use the loss (it's not that informative). To compute a metric that has immediate meaning for us, we can compute the accuracy. In a multi-class setting, we have to count the number of labels that are equal to the targets, and divide by the total number of predictions. If we load the data in batches, we have to compute the accuracy as incremental."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT6-lrXknHnp",
        "outputId": "6e69b6fc-01f8-4975-ef6f-840fe25562a0"
      },
      "outputs": [],
      "source": [
        "accuracy = 0.0\n",
        "total = 0\n",
        "for samples, labels in val_loader:\n",
        "    ...\n",
        "accuracy = accuracy / total\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, finally, let's report an improved training loop. Here we are also tracking the loss across the iterations and evaluating at each epoch. Moreover, we are also adding the instruction to load the data and model to a custom device (e.g., a GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ota6WvslpSke",
        "outputId": "416e3514-b7e4-4218-cd2d-9e8cc722b0c8"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-2\n",
        "epochs = 5\n",
        "device = torch.device('cpu')\n",
        "net = MNISTModel()\n",
        "net.to(device)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, scheduler, loss_fn):\n",
        "    train_loss = 0.0\n",
        "    total = 0\n",
        "    for samples, labels in train_loader:\n",
        "        samples, labels = samples.to(device), labels.to(device)\n",
        "        outputs = model(samples)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += samples.shape[0]\n",
        "        train_loss += loss.sum().detach()\n",
        "    train_loss /= total\n",
        "    scheduler.step(train_loss)\n",
        "    return train_loss.item()\n",
        "\n",
        "def valid_epoch(model, val_loader, loss_fn):\n",
        "    accuracy = 0.0\n",
        "    validation_loss = 0.0\n",
        "    total = 0\n",
        "    for samples, labels in val_loader:\n",
        "        samples, labels = samples.to(device), labels.to(device)\n",
        "        outputs = net(samples)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        predictions = outputs.argmax(dim=1)\n",
        "        accuracy += (predictions.type(labels.dtype) == labels).float().sum()\n",
        "        total += samples.shape[0]\n",
        "        validation_loss += loss.sum()\n",
        "    validation_loss /= total\n",
        "    accuracy = accuracy / total\n",
        "    return validation_loss.item(), accuracy.item()\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_epoch(net, train_loader, optimizer, scheduler, loss_fn)\n",
        "    val_loss, accuracy = valid_epoch(net, val_loader, loss_fn)\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    print(epoch, accuracy)\n",
        "\n",
        "# save the model\n",
        "torch.save(net.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we tracked the loss, we can also visualize it in a plot. Let's plot the training and validation loss. \n",
        "Observe that if the validation loss starts increasing (while the training loss keeps becoming smaller), this can be indication of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "1cGQOFG3r7aC",
        "outputId": "e7910d0a-058a-437c-de0c-8993a64d6e01"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(val_losses, label='validation loss')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's finally understand what are the limitations of the fully-connected models. These models learn a function by considering all correlations between each combination of pixels in the image. However, for us, locality is much more important. \n",
        "As we ravel the images, we loose for instance the 2D structure of the image. For the model, this information is passed as raw, thus it will be equally important to connect pixels that are neighbors and pixels that are far away from each other.\n",
        "\n",
        "Now we introduce a disturbance, where we shift the image and check performances of the model. \n",
        "\n",
        "The model is learning spurious correlations and also it is missing important information related to the locality of the pixels w.r.t. their neighborhood!\n",
        "\n",
        "However, while the performance of the model drops substantially, the image for us still looks unchanged and we are able to recognize the digit. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "_dKnRdSZOWZg",
        "outputId": "16d69726-ef19-4e14-f71c-25219ef9b091"
      },
      "outputs": [],
      "source": [
        "def shift_pixels(t):\n",
        "    shift = 3\n",
        "    return torch.roll(t, shift)\n",
        "\n",
        "# let's see how the network generalizes\n",
        "augmented_mnist_validation = datasets.MNIST(data_path, train=False,\n",
        "                                              download=False,\n",
        "                                              transform=transforms.Compose([\n",
        "                                              transforms.ToTensor(),\n",
        "                                              transforms.Lambda(shift_pixels),\n",
        "                                              normalize,]))\n",
        "augmented_val_loader = torch.utils.data.DataLoader(augmented_mnist_validation,\n",
        "                                         batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "images, labels = augmented_mnist_validation[0]\n",
        "display_image(images, labels)\n",
        "\n",
        "val_loss_augmented, accuracy_augmented = valid_epoch(net, augmented_val_loader, loss_fn)\n",
        "\n",
        "print(\"accuracy: \", accuracy, \"accuracy after augmentation:\", accuracy_augmented)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notebook with complete code:\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/battistabiggio/ai4dev/blob/main/notebooks/AI4Dev_05_dnns_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
