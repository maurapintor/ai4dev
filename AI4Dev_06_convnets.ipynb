{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/maurapintor/ai4dev/blob/main/AI4Dev_06_convnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convolutional Neural Networks (and some other tricks)\n",
        "\n",
        "In this notebook, we will see how to implement a convolutional neural network in PyTorch. These models use discrete convolutions to process the images. \n",
        "\n",
        "With deep learning, we can combine convolutions and downsampling to extract higher-level information from the images. The goal is to **learn** the best filters to extract features that lead to lower loss values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This time we will use the CIFAR10 dataset, composed of RGB images (3 channels) of size $32 \\times 32$\n",
        "\n",
        "Note that we specify the number of input channels and the number of output channels. Additionally, there are parameters that affect the dimension of the filter and further processing on the convolutions.\n",
        "\n",
        "After each filter, the size of each channel in the output is determined by:\n",
        "\n",
        "$$\n",
        "Z = \\frac{W - K + 2P}{S} + 1\n",
        "$$\n",
        "\n",
        "* W = width of the image (consider square images)\n",
        "* K = kernel size (also square)\n",
        "* P = padding (to frame the image, usually so that we can make this ratio an integer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Layer math for our network:\n",
        "\n",
        "$$\n",
        "Z = \\frac{W - K + 2P}{S} + 1\n",
        "$$\n",
        "\n",
        "* Input `(batch_size, 3, 32, 32)`\n",
        "* Conv layer, `in_channels=3`, `K=3`, `P=1`, `out_channels=16`\n",
        "  * output = 16 channels of of width and height $\\frac{32 - 3 + 2(1)}{1} + 1 = 32$\n",
        "* MaxPool, `K=2` -> output = 16 channels of size $\\frac{32}{2} = 16$\n",
        "* Conv layer, `in_channels=16`, `K=3`, `P=1`, `out_channels=8`\n",
        "  * output = 8 channels of of width and height $\\frac{16 - 3 + 2(1)}{1} + 1 = 16$\n",
        "* MaxPool, `K=2`\n",
        "  * output = 8 channels of width and height $\\frac{16}{2} = 8$\n",
        "* Linear (fully-connected) Layer of input size $w \\times h \\times c = 8 \\times 8 \\times 8$ and $32$ output units\n",
        "* Linear (fully-connected) Layer of input size $32$ and output $10$ as the $10$ output classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDnm5_cRfSb9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)  # see layer math above\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can load the CIFAR10 dataset from torchvision, similarly to what we did with the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J8rS9uxVnBc",
        "outputId": "b8cd620b-6c70-4c2b-e536-52ac40c5f6fa"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))  # mean and std for CIFAR10\n",
        "])\n",
        "\n",
        "data_path = 'data'\n",
        "cifar_train = datasets.CIFAR10(data_path,\n",
        "                             train=True,\n",
        "                             download=True,\n",
        "                               transform=transf)\n",
        "cifar_validation = datasets.CIFAR10(data_path,\n",
        "                                  train=False,\n",
        "                                  download=True, transform=transf)\n",
        "\n",
        "print(\"samples in training dataset: \", len(cifar_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HixcFFvW5eu"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar_train,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(cifar_validation,\n",
        "                                         batch_size=64,\n",
        "                                         shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can finally write the training loop. We are going to use a function for the training epochs and one for the validation epochs, and additionally we can track the loss values to inspect them later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt24EtkTWPqk",
        "outputId": "69a2efb4-31ed-4008-e021-e5b127bd67aa"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-2\n",
        "epochs = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net = Net()\n",
        "net.to(device)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, scheduler, loss_fn):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    total = 0\n",
        "    for samples, labels in train_loader:\n",
        "        samples, labels = samples.to(device), labels.to(device)\n",
        "        outputs = model(samples)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += samples.shape[0]\n",
        "        train_loss += loss.sum().detach()\n",
        "    train_loss /= total\n",
        "    scheduler.step()\n",
        "    return train_loss.item()\n",
        "\n",
        "def valid_epoch(model, val_loader, loss_fn):\n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    validation_loss = 0.0\n",
        "    total = 0\n",
        "    for samples, labels in val_loader:\n",
        "        samples, labels = samples.to(device), labels.to(device)\n",
        "        outputs = net(samples)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        predictions = outputs.argmax(dim=1)\n",
        "        accuracy += (predictions.type(labels.dtype) == labels).float().sum()\n",
        "        total += samples.shape[0]\n",
        "        validation_loss += loss.sum()\n",
        "    validation_loss /= total\n",
        "    accuracy = accuracy / total\n",
        "    return validation_loss.item(), accuracy.item()\n",
        "\n",
        "train_losses, val_losses, accuracies = [], [], []\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_epoch(net, train_loader, optimizer, scheduler, loss_fn)\n",
        "    val_loss, accuracy = valid_epoch(net, val_loader, loss_fn)\n",
        "    print(f\"epoch: {epoch}, validation accuracy: {accuracy}\")\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now plot the values we tracked:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(train_losses, color=\"green\", label=\"train\")\n",
        "plt.plot(val_losses, color=\"blue\", label=\"validation\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(accuracies, color=\"blue\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try to save the model and load it again, and check that the loaded model behaves exactly as the previously-saved one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uI4wuVwZ5iM"
      },
      "outputs": [],
      "source": [
        "model_path = 'cifar_model.pt'\n",
        "torch.save(net.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxnhKd0_aHjB",
        "outputId": "64680747-1b5e-4eee-ff70-af94506816b2"
      },
      "outputs": [],
      "source": [
        "new_model = Net()\n",
        "new_model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "new_model.eval()\n",
        "val_loss, accuracy = valid_epoch(new_model, val_loader, loss_fn)\n",
        "print(\"accuracy of the loaded model: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helping our model to converge and generalize: Regularization\n",
        "\n",
        "The tools aimed at easing generalization are usually referred to as **generalization**.\n",
        "\n",
        "* The first way to stabilize generalization is to add a regularization term to the loss. This makes the loss have a smoother topography, and there’s relatively less to gain from fitting individual samples. We can add weight penalty either by encapsulating the norm in the loss (and use autograd on it), or by adding `weight_decay` in the optimizer.\n",
        "\n",
        "$$L(\\mathbf{x}, y; \\boldsymbol{\\theta})  + \\lambda ||\\boldsymbol{\\theta}||_p$$\n",
        "\n",
        "* Another way is to use dropout: zero out a random fraction of outputs from neurons across the network, where the randomization happens at each training iteration, giving neurons in the model less chance to coordinate in the memorization process that happens during overfitting. In PyTorch, we can implement dropout in a model by adding an `nn.Dropout` module, in which we specify the **probability** with which inputs will be zeroed out. Note that dropout is normally active **during training**, while during the evaluation of a trained model in production, dropout is bypassed or, equivalently, assigned a probability equal to zero.\n",
        "\n",
        "* Finally, we can keep the activations in check with batch normalization: we rescale the inputs to the activations of the network so that minibatches have a certain desirable distribution, avoiding the inputs to activation functions being too far into the saturated portion of the function, as they risk killing gradients and slowing training. Just as for dropout, batch normalization needs to behave differently during training and inference. In fact, at inference time, we want to avoid having the output for a specific input depend on the statistics of the other inputs we're presenting to the model.\n",
        "\n",
        "We finally know what the `model.train()` and `model.eval()` are for. In the case of dropout, the `model.eval()` assigns a zero probability of dropout for the model's neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, drop=0.5):\n",
        "        super(SmallCNN, self).__init__()\n",
        "        self.num_channels = 3\n",
        "        self.num_labels = 10\n",
        "        activ = nn.ReLU(True)\n",
        "        self.feature_extractor = nn.Sequential(OrderedDict([\n",
        "            ('conv1', nn.Conv2d(self.num_channels, 32, 3)),\n",
        "            ('relu1', activ),\n",
        "            ('conv2', nn.Conv2d(32, 32, 3)),\n",
        "            ('relu2', activ),\n",
        "            ('maxpool1', nn.MaxPool2d(2, 2)),\n",
        "            ('conv3', nn.Conv2d(32, 64, 3)),\n",
        "            ('relu3', activ),\n",
        "            ('conv4', nn.Conv2d(64, 64, 3)),\n",
        "            ('relu4', activ),\n",
        "            ('maxpool2', nn.MaxPool2d(2, 2)),\n",
        "        ]))\n",
        "        self.classifier = nn.Sequential(OrderedDict([\n",
        "            ('fc1', nn.Linear(64 * 4 * 4, 200)),\n",
        "            ('relu1', activ),\n",
        "            ('drop', nn.Dropout(drop)),\n",
        "            ('fc2', nn.Linear(200, 200)),\n",
        "            ('relu2', activ),\n",
        "            ('fc3', nn.Linear(200, self.num_labels)),\n",
        "        ]))\n",
        "\n",
        "    def forward(self, input):\n",
        "        features = self.feature_extractor(input)\n",
        "        logits = self.classifier(features.view(-1, 64 * 4 * 4))\n",
        "        return logits\n",
        "    \n",
        "net = SmallCNN()\n",
        "learning_rate = 1e-2\n",
        "epochs = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net = Net()\n",
        "net.to(device)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_losses, val_losses, accuracies = [], [], []\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_epoch(net, train_loader, optimizer, scheduler, loss_fn)\n",
        "    val_loss, accuracy = valid_epoch(net, val_loader, loss_fn)\n",
        "    print(f\"epoch: {epoch}, validation accuracy: {accuracy}\")\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(train_losses, color=\"green\", label=\"train\")\n",
        "plt.plot(val_losses, color=\"blue\", label=\"validation\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(accuracies, color=\"blue\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(t, title=None):\n",
        "    \"\"\"Display image for Tensor.\"\"\"\n",
        "    t = t.numpy().transpose((1, 2, 0))\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
        "    std = torch.tensor([0.229, 0.224, 0.225])\n",
        "    t = std * t + mean\n",
        "    t = torch.clip(t, 0, 1)\n",
        "    plt.axis(\"off\") \n",
        "    plt.imshow(t)\n",
        "\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "images, labels = next(iter(val_loader))\n",
        "cifar_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  \n",
        "num_images = 10\n",
        "fig = plt.figure(figsize=(2*num_images, 2))\n",
        "for i, (image, label) in enumerate(zip(images, labels)):\n",
        "    if i == num_images:\n",
        "        break\n",
        "    pred = net(image).argmax(dim=1)\n",
        "    fig.add_subplot(1, num_images, i+1)\n",
        "    imshow(image, title=f\"pred={cifar_labels[pred]}\\ntrue={cifar_labels[label]} \")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notebook with complete code:\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/battistabiggio/ai4dev/blob/main/notebooks/AI4Dev_06_convnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
